Chapter 2:

# An Internet Built around Consumption Is a Bad Place to Live

## Cityscapes, as Imagined by Sigmund Freud and Jane Jacobs

<*p. 12*> Sigmund Freud has been described as "a frustrated archaeologist." The idea of cities and their ruins, and the layers of history they contain, was a metaphor that he returned to repeatedly in his writing. (On a personal level, he also collected thousands of antiquities, perhaps as a kind of performative psychoanalysis.) In the opening pages of one of his later works, *Civilization and Its Discontents*, Freud discusses the history of a city repeatedly built and rebuilt over time, using it to represent the human mind.

Rome, for example, became the global metropolis it now is over the course of thousands of years. People had lived in the area for millennia, and the city itself began as a collection of pastoral settlements on the Palatine Hill. As villages developed on various surrounding slopes, they formed a federation of sorts before a monarchy took control of the area around 800 BCE. This eventually transformed into a republic, which grew in power and influence and ultimately extended its empire across the Mediterranean.

The modern city of Rome looks very different from how it began. But any visitor to Rome today can see evidence of its ancient <*p. 13*> history everywhere. There are the old buildings that have lasted for centuries, as modern constructions rose around them. Beneath the buildings and infrastructure lie layers of rubble and detritus fron generations past. Most spectacularly, the Forum displays its ruins for all to see, a rich seam of history through the center of the city. It gives solid evidence of the long and powerful reign of the Roman Empire, even if some imagination is required to conjure a vision of its glory days.

A city like Rome has inevitably evolved around certain definitive forces of nature, such as waterways and cliffs. It is possible to transform these topographical influences with the help of diggers and dynamite. Sometimes this kind of modification of the natural world is necessary for the residents, with road tunnels hacked through mountains and sewerage pipes buried underground, but in most respects humanity concedes to the landscape.

All this, Freud surmised, is not unlike the human mind. Historical experiences build up in our heads over time, with a persistent hold over the present. Some forces that create the topography of the psyche reside in the unconscious, like natural features of a landscape, resilient and sometimes difficult to control. Other influences are a result of the social context we exist in and respond to, like buildings dilapidated and rebuilt, determining the urban structure and layout. A comprehensive picture of the human mind requires proper analysis of all these elements and how they fit together.

Freud was quick to point out the limits of such a metaphor, and on other occasions he left its significance unstated or its meaning incomplete. A more precise analogy with the human mind, Freud insisted, would involve a visitor to Rome seeing it all at once its past and its present, with buildings of multiple temporalities visible together. Real estate in cities is almost always in short supply, whereas the human mind knows no such material limitations, so the comparison can only take us so far. But there is something in the social complexity and the historical physicality of a city that gives the metaphor an enduring appeal. Freud's ideas, including his proposition that our minds work both unconsciously and consciously, and that they are a <*p. 14*> product of their history as well as their present, align neatly with the various influences that dictate how a city is built.

Many Freudian concepts are taken for granted today. But at the time he was writing, in the early twentieth century, they were a revolutionary approach to understanding the psyche. Questions about the intersection of agency, influence, pathology and plasticity within the mind were opened up by Freud in unprecedented ways. They are questions that help us consider how digital technology has affected our thinking and behavior. As our world becomes a place where we live and work with devices constantly at our disposal, it is worth thinking critically about how the evolution, design and regulation of digital technology bear upon our ability to build a rational psyche that is fulfilled, joyful and socially functional. Cities are planned in certain ways, to protect heritage, build sustainability and preserve amenity, so we can experience spaces differently according to our needs. They can also be designed for the purposes of social control, to limit particular interactions. Who exercises the power of design is a significant question. Given the enormous influence of digital technology on how our minds work, we need to find ways to make sure that it functions consistently with what is necessary to maintain a healthy and effective mind--the equivalent of a well-planned city.

Digital technology has put us in a bind. We have good cause to be suspicious of how much our personal engagements with it are influencing our behavior, but we are short of meaningful ways to challenge these effects. Or, as Walter Kirn put it, "if you're nor paranoid, you're crazy." Companies are using digital technology to collect data about us on a larger scale than ever before, in ways that are far more revealing about our inner lives. It is like occupying a city where the topography changes daily. Fewer parks and gardens, more shopping malls; less mountainous horizons, more flashing billboards. Digital technology is creating a history of our sense of self that is tightly bound up with the market: the space of our mind is increasingly being defined by our consumption, for the purposes of further consumption. As digital technology develops at a dizzying pace, integrating itself further into our personal spaces, political <*p. 15*> communities and workplaces, each new advance is used to learn more about us at more intimate levels and map the contours of our psyche more intricately, often without our knowledge.

Framing is important here. Companies collect data, rather than--as is often claimed--we give it away willingly. Both constructions of the process are technically true, in the sense that the collection of our data is impossible without our formal consent, but that provides only a very limited picture of the phenomenon. Consent is in no way meaningful when online spaces are designed around the expectation that it will be given and rarely offer users an active choice in how their data will be used or managed. It is as though obtaining consent were a mere formality, secondary to another purpose.

Corporate surveillance is creating a robust social graph of our existence. To see this as a problem of personal, individual responsibility would be to miss the broader, systemic context. For this reason, framing these discussions around the idea of privacy--understood as an inherently personal right--falls short. The idea of privacy is too often a blunt substitute for notions such as agency, spiritual nourishment, and freedom from control. Privacy, as it is commonly understood and deployed, cannot help us understand how to avoid manipulation of both our unconscious and our conscience (or super-ego as Freud would put it); it is an inadequate description of a desire for space to build a functional ego that can rationally pursue a personal direction while simultaneously navigating the various compromises of living in a society.

The Internet is not just pipes and switches, and the web is more than hypertext; cyberspace is a place in which we engage with the world, and the forces that shape this place have influence on us. The structures surrounding our personal experience online are the focus of much commercial interest and investment, so much so that any meaningful struggle to create space for our inner self, for a literal form of self-determination, has to begin with an analysis outside of the self. No one would expect to find a moment of quiet reflection in the middle of Times Square or Shibuya Crossing. But everyone would be concerned if the spaces of beauty that might be perfect <*p. 16*> for this purpose--public gardens, monuments, art galleries--were being bought up and demolished to make more space for shopping meccas and strip malls. How we engage with the world on an individual level is deeply connected to the context we find ourselves in and the social forces it represents.

There is a growing awareness of the scandalously invasive way in which we are surveilled by data miners and marketers to predict and control our behavior for the purposes of making money. Cambridge Analytica is a good example. The company harvested data from Facebook via a personality quiz taken by tens of millions of people, and their friends, by stealth. Users, civil society groups and lawmakers were outraged that Facebook could treat our information so carelessly and that this information went on to become fodder for a powerful, profitable industry.

As we learn more about the ways in which we are identified, categorized and manipulated, technology races ahead, becoming ever more sophisticated and elusive. But while some of the invasive uses of digital technology can seem overwhelming, the battle for control of our destinies has not yet been lost to the age of the data boom--there is time to take charge of these processes before they take further charge of us. By learning and ultimately understanding, we can find ways to create space for our authentic selves in the digital age.

---

The idea that your phone is listening to you, or that your computer is watching you, is becoming accepted as a reality of life. To many of us, our personal data might seem deathly boring or perhaps individually embarrassing, but we increasingly recognize its value to unseen, shadowy forces such as data miners and marketers. Their activities do, after all, drive the economic powerhouse of Silicon Valley and explain how companies can be worth billions of dollars while offering us services supposedly for free. In the past, data collection and consumer analysis might have happened through subscription services or loyalty card schemes, something that was opt-in. But now that we spend large amounts of time online, whether at a computer <*p. 17*> or on a smartphone, the opportunities to collect this information have exploded. The pursuit of big data has created an army of cyber vampire squids, relentlessly jamming their blood funnels into anything that smells like it could be monetized.

Perhaps most iconically, this phenomenon caught the attention of the public when Target Corporation predicted a teen was pregnant before her own parents knew. Andrew Pole, a statistician for the company since 2002, was running tests on the data the company had on consumers to figure out how to leverage this for more effective marketing. Target had long collected customers' data and would send them personalized coupon booklets, based on past purchases, to draw them back to the store. "We do that for grocery products all the time," a Target executive nonchalantly told the *New York Times* for a story in 2012. As a statistician, Pole's objective was even more precise: find the right moment to market to consumers and change their shopping habits to win their loyalty to the store. His job was "to identify those unique moments in consumers' lives when their shopping habits become particularly flexible and the right advertisement or coupon would cause them to begin spending in new ways." Far and away, the most unique moment from this perspective is the birth of a baby. Babies represent a moment of flux: when old shopping habits crumble under the weight of caring for a new human, marketers have a precious chance to cultivate new behaviors.

Pole's tests produced a number of ways to predict when a baby was due, so that marketing material could target that customer before delivery and ahead of the competition. (Birth records are usually public; if Target waited for this data to initiate its marketing campaign, it would be lost among all the other companies doing the same.) Pole's model picked up the kinds of shopping habits that marked the beginning of a woman's third trimester. Hence the arrival of a whole bunch of ads for maternity clothes, lotion and diapers addressed to a high-school student, to the outrage of her father, who laid into the local store manager for inappropriately encouraging his daughter to fall pregnant. The father later apologized. It turned out the company had known something before he did.

<*p. 18*> These methodologies for predicting and shaping our behavior have grown more sophisticated over the first two decades of the twenty-first century. Collection and analysis of big data about people is a well-established industry. It includes the companies collecting data (miners), those trading it (brokers) and those using it to generate advertising messages (marketers), often with overlap between all three. It can be hard to obtain reliable estimates of the size of the industry, given its complexity, but one study says that by 2012 it was worth around $156 billion in the United States and accounted for 675,000 jobs. It has undoubtedly grown since then. Like slum landlords who rent out dilapidated apartments, or greedy hotshot developers who take advantage of legal loopholes to build luxury condos, companies that trade in personal data represent the sleazy side of how digital technology is impacting the real estate of our minds. This industry uses the faux luxuries of choice and convenience to entice us to part with our data, but often what they are really selling is overpriced and dodgy.

Via desktop computers or laptops, companies can collect information about us using a variety of methods, from what you click on to how long your mouse lingers. This involves the use of cookies, stored in the browser so companies can later track where you go by pinging messages back to the company servers that left them there. Such information can then be matched to other data sets, including financial information, purchasing histories and assumptions about health conditions.

Extracting personal data from smartphones is a more complex task than from personal computers. Unlike on a computer--where we often spend our time in a single browser that quickly accumulates cookies that can be analyzed--data on smartphones is often siloed into various apps, without much engagement between them. But this data is also much more valuable: we carry our phones with us on our person almost all the time, and each device has its own unique identification number. Retailers rely on beacons to pinpoint your location and provide what analysts describe as "a more customized approach to in-store shopping." If they can get their hands <*p. 19*> on your IP address, often via the operating system, marketers can know when you walk past a store. Lots of popular free apps also have standard terms that involve accessing significant amounts of personal data, including things like locational information, which is another way to know a user's whereabouts if the operating system settings are turned off. These apps (flashlight apps are perhaps the most notorious) act like digital Trojan horses, with users downloading them without realizing they are a back door for data miners. The race to improve the capacity of smartphone technology to provide a richer picture of user behavior represents an important frontier for the data boom, and it is likely to be a continuing focus into the future.

This kind of tracking is also happening between devices connected to the Internet--from television set-top boxes to smart fridges. One method for cross-device identification involves the use of ultrasonic frequencies inaudible to humans. The sounds play in television or browser ads and can be picked up by smartphones. This can track what ads a person sees and, by linking devices, whether they respond to the messaging by searching for or buying a product. The potential of smart televisions to use data collected from your different devices, combined with independent data sets, is transforming the idea of personalized ads, something the advertising industry is highly enthusiastic about.

These advances make it very difficult to meaningfully know, let alone limit, what information is known about you by others. The technological infrastructure around our online behavior and our physical presence is constantly observing what we do. As the Center for Digital Democracy describes it, this cross-referencing "has effectively erased any privacy safeguards we may have enjoyed previously when we switched between devices." Switching browser programs used to be another effective way of preventing data miners from collecting a complete picture of your activities on a computer, but this is changing. Browsers perform a range of tasks as we use them, loading graphics and using plugins, for example, and computers will have certain settings, such as a time zone, all of which <*p. 20*> are specific to individuals. Taken together, these can allow a user to be identified with over 99 percent accuracy.

The industry is also adopting various forms of biometric profiling, including using keystroke patterns. How we type is marked by minute differences, which can create a biometric profile of individuals and even be matched to emotional states. Thus you might be identified even when using an anonymized browser, such as The Onion Router (Tor), or when using a different computer. Facial recognition software is already prevalent in the retail industry, and increasingly it is being matched to other data sets and used with beacons to push advertising onto smartphones. Over time, marketing that connects our different behaviors together--on the street, in the home, at work--will be the norm.

All this together means that the data mining industry is enormous and increasingly difficult to evade. While it is easy to see how Facebook and Google obtain enormous amounts of our data, there are dozens of more shadowy companies that do the same on an even larger scale. These companies are not household names, yet they hold countless intimate details about us on their digital ledgers. We find ourselves walking through a city of private eyes and pickpockets, constantly watched by closed-circuit cameras that fade into the backdrop of urban life. This intensive examination and analysis of our behavior by private companies is what Shoshana Zuboff ha called "surveillance capitalism"--companies snooping on us for the purposes of selling things. It sits on the very edge of technological development, sucking resources into its projects, and often involves obscure companies as well as mainstream platforms. Together the industry holds billions of pieces of information on billions of people. As the advocacy organization StopDataMining put it: "If iron ore was the raw material that enriched the steel baron Andrew Carnegie in the Industrial Age, personal data is what fuels the barons of the Internet age."

---

One of the problems that arises in these discussions is metonymy: privacy is a single word that describes all manner of dastardly <*p. 21*> approaches to information management. It is a term often used by companies in transactional, technocratic ways, ignoring the conceptual and material implications of their approach. Secrecy, security and anonymity all describe slightly different components of privacy but regularly end up lumped together. Secrecy covers the confidentiality of a communication--that is, secrecy exists when the substance of a message is known only to the sender and the intended recipient. Security is about the integrity of communication channels and certain spaces (be they physical or cyber), to ensure they are free from invasion by uninvited parties. Perhaps most importantly for our present purposes, privacy is often used interchangeably with anonymity--that is, where information collected is separate from the name of the person it is collected from. Many companies that talk about privacy only offer in reality one, maybe two, of these guarantees. Such a promise is a fudge. Or as the Center for Digital Democracy puts it: "This is merely a 'don't-look-too-closely' claim designed to head off the scrutiny their practices require."

There are two reasons for being skeptical of the promise of "anonymous" or depersonalized data. First, on a practical level, anonymity is brittle. It is easy to identify someone using only a few data points. Way back in 2000, professor Latanya Sweeney found that 87 percent of Americans could be uniquely identified using only their ZIP code, gender, and date of birth. So, for what it's worth, the more information companies collect and hold, even if it is held nominally separately from our name, the easier it gets for someone to reverse-engineer this to link the data to us. To protect ourselves from harm, we are dependent on companies protecting our data, even if it is de-identified or innocuous, at a time when leaks and hacks are commonplace.

Second, on a more abstract level, the protection of privacy offered by anonymity alone is minimal. Companies create identities for us based on this data, without any accountability or capacity for us to change them. Our *abstract identities*, if we understand that to mean our social, political and economic preferences as determined by the data collected about us, are generated and then repeatedly <*p. 22*> refined and used to determine advertising for us. Data points lead to assumptions about relevant marketing, which lead to further data points that make up your abstract identity. It creates a form of path dependency: once the vast and obscure apparatus of data-driven advertising takes a particular course, the choices it makes about you are constrained by its previous choices. These abstract identities follow us around online, even if they are not attached to our name, like zombies. They are beyond our control. In this light, the absence of a name attached to that identity offers scant protection from anything meaningful. Data collection and curation, even when done in ways that protect our anonymity, limit our freedom individually and collectively.

This process of *abstract identification* curtails autonomy by creating a summary of your personality--thoughts, needs, desires, and especially vulnerabilities--extracted from data generated online. Using the highly selective body of information, this process creates a history of your sense of self that serves to influence you. You are stripped of your agency; lacking the capacity to control what is known about you and by whom, your ability to make decisions for yourself is impaired.

Autonomy, then, is the other essential aspect of privacy that is rarely given its full meaning in mainstream discussion of the topic. Secrecy, security and anonymity are all important, but autonomy is too often ignored, reducing privacy to a transactional concept, depoliticizing it and confining it to the atomized individual. Allowing others to write a history of our sense of self forecloses the possible futures available to us. "Privacy is the right to a self," declared the whistleblower Edward Snowden. "Privacy is what gives you the ability to share with the world who you are on your own terms." It is the bridge between the individual and the social, between our selves and our context. To give the idea of privacy the richness it needs in order to be meaningful requires that we understand it collectively, as a function of power.

Many data miners and marketers are not concerned with who you are in the real world, but they are highly interested in your abstract <*p. 23*> identity (your suburb or city, for example, or your car model and make). They are not bothered about linking this to an actual name or physical presence. For the most part, they are only interested in you as a consumer, someone who buys and who can be convinced to buy; a data point that fits into collective trends or cohorts of people who behave similarly, someone who can be predicted to behave in certain ways in response to particular stimuli.

Freud's thinking gains new relevance in this context. By understanding that our mind is made up of both a conscious and an unconscious, we can start to appreciate how our existence in the digital age is not just a matter of choice, nor is it simply driven by our own free will. Freud explored the idea that mental processes are driven by both the pleasure principle and the death drive. Our minds, he argued, are motivated by the "production of pleasure," an observation that is easy to identify with. But we are not all simply hedonists, and to some degree we must temper our desire for pleasure with the limitations of living in a society, what Freud called the reality principle. And, he said, we also possess a self-destructive tendency, or death drive, manifested perhaps most prominently in survivors of trauma or pain who repeat thoughts and actions associated with those experiences. This comes from a desire to overcome that past event: "to work over in the mind some overpowering experience so as to make oneself master of it." These kinds of influences on our mental processes can be subject to manipulation or intervention, be it by the analyst or by others with less therapeutic motives.

In the digital age, these features of our psychology are subject to manipulation in all sorts of ways now that our social interactions and material consumption increasingly occur online. As marketing budgets grow and companies spend more on mapping the content of our abstract identities, it starts to look like a hopelessly mismatched battle of wits. It is not that we are all dupes. When marketers know both what kind of pleasure we desire and what kind of self-destructive habits we practice, it gives them an enormous amount of power in a context in which many of these behaviors find expression online.

<*p. 24*> Freudian ideas, and the broader body of thought around psychoanalysis, provide insight, even hope. They encourage us to appreciate the power of the individual to come to know what is unknown, to identify manipulation even when it might be well concealed. Psychoanalysts argue that we have the capacity to make conscious what we have hidden or repressed in the unconscious--trauma, forbidden desire or other experiences. And the unconscious exists as "neither individual nor collective," writes the philosopher Mladen Dolar, but rather "precisely between the two, in the very establishment of the ties between an individual (becoming a subject) and a group to which s/he would belong." In other words, there is a dialectic process at play between the social forces that shape us and our own personality. While the data mining industry might seek to make use of this for its own commercial ends, resistance is not impossible.

A city is a conscious attempt to collectively dominate nature--to build onto the natural world so as to protect citizens against the elements. But there is also an impulse to maintain something of the natural green spaces in our urban environments, in an effort to keep cities sustainable and perhaps remind us of the vast and intricate network of life that exists in the land, water and sky all around. We will always be required to mold our temperaments to accommodate the experience of living in society, but our minds need room to breathe and space to explore possibilities of independence and collaboration, free from corporate agendas. Finding the right balance between the constructed and natural environments is a challenging task, and this holds true for our psyches also.

---

The most valuable consumer platforms have both the capacity to collect highly valuable personal data and the opportunity to use it to market to users at the most lucrative moments of their daily lives. These are the places in which the invisible hand of what I call *technology capitalism* is at work--between data miners and advertisers, with data on users as the commodity being traded.

For our present purposes, I will define technology capitalism as the leading edge of the technology industry, a system led by a <*p. 25*> class of people who are focused on orienting digital technology toward market-based systems of profit. My aim is to use the term to demarcate the active parts of this modern industry, rather than use it as a generalized description of capitalism as transformed by technology.

These platforms are the places in the digital age where personal data is centralized and then used to segregate us into different audiences of consumers. Amazon has a record of all you have purchased and everything you view and uses it to generate specific ads and differential pricing based on where you live and other personal information. Google has a log of all your search histories, your emails, your YouTube views, your Nest data, and your locational information using maps, which it uses to generate personalized advertising. Every Facebook like and share button you see is tracking you, even if you are logged off Facebook, regardless of whether you click on the button. (These buttons are actually small pieces of code, which instruct the browser to contact Facebook's servers when you land on the site.) The same is true for websites with embedded YouTube videos, which feed data back to Google. This all feeds into a database of your habits and interests. Sometimes these companies also purchase data to bulk out their own pool. Together they have highly sophisticated and well-used platforms that can be relied on for creating a picture of your abstract identity.

This system of observational intelligence, scattered across the web, is then used to curate our singular sense of self, that is, our real-world understanding of our own personalities. "The advantage that Facebook and Google have over the regular data on-boarders is twofold," writes Antonio García Martínez, a former product manager in the Facebook ads team. "They have much more of your personal data, and they see you online all the time." That is, they have the capacity to collect rich and diversified data and to then use it to deliver compelling marketing messages. "Facebook, Google, and others have achieved the holy grail of all marketers," he continues. "A high-fidelity, persistent, and immutable pseudonym for every consumer online." The more a marketer knows about you, the <*p. 26*> better the ad; and the more time you spend on a particular platform, the more valuable the digital real estate.

The precision is impressive. A ProPublica investigation found that Facebook offers advertisers more than 1,300 categories of users to allow them to carefully direct their messages: "everything from people whose property size is less than .26 acres to households with exactly seven credit cards." Your own history of your sense of self when documented by these platforms, works to determine your future. This is how technology capitalism dominates our personal experience of digital life. We might think we are in a public square or community-owned garden, but in reality we are not living in the same exact city as anyone else.

For these reasons, no two people's experience of the web will be the same; websites are put together based on our abstract identities. Professor Joseph Turow compares this to selling by peddlers in centuries past, versus the experience of the shopping mall. Shopping malls were a space where everyone had access to the same goods, for the same price. Peddlers--the old way of buying an selling--traveled door to door, sizing you up according to the look of your home, remembering what you bought from them last time. "Peddlers evaluated you based on their relationship with you, they changed their prices based on what they thought you could afford," says Turow. "There was all this negotiation back and forth." In the wake of the digital revolution we are returning to the peddling mode, where products are presented to you based on information about your preferences, status and vulnerabilities, and prices are increasingly set for each specific consumer. As Michael Fertik, the founder of Reputation.com, bluntly put it: "The rich see a different Internet than the poor." With the move away from the public space of a mall or market square to individually tailored transactions, Turow argues we are experiencing "a major transformation of what it means to buy and sell in the public sphere." It challenges the very idea that the Internet is a public space.

The justification for this process of abstract identification and segregation is often framed in the nebulous discourse of consumer <*p. 27*> choice. Jeff Bezos, CEO of Amazon, reportedly reserves a seat at the conference room table known as "the empty chair." At meetings, Bezos reminds attendees that this represents "the most important person in the room," namely the customer. Data collected by social media or otherwise is often presented as a way of giving consumers access to relevant advertising and offers that may be of interest to them. Indeed, one of the largest data miners, Acxiom, has encouraged people to look up the data it holds about them to correct any mistakes. In other words, Acxiom was asking people to more actively engage in the process of abstract identification--a highly valuable, low-cost exercise for them.

In this way, data mining is framed as a supposedly evenhanded power relationship in which consumers are invited to dictate to large corporations how they want to live their lives online. We are told that the process of abstract identification is something that benefits us all, individually and collectively, that it can even be empowering. This is an effective but misleading portrayal of the dynamics at work. It is not unlike a city authority permitting the razing of historic districts or lively green spaces to make way for the construction of parking lots and luxury stores. While we all get to walk past and peer into these expensive buildings--and theoretically we all have the freedom of choice to make use of them--they occupy spaces that previously held relevance for all residents and now benefit only a select few. They frame our expectations around the meaning of success and pleasure. Such projects are a great outcome for property developers and their wealthy clients, less so for the rest of us.

Surveillance capitalism yokes us to a certain history of our sense of self, which is constantly updated and channeled into a vision of our own future. Collectively we rehearse the experience of being a consumer in all our communities every day, and we practice letting companies collect our personal information, so that it feels normal. We learn to relinquish the idea that there should be spaces free from this dynamic. We grow accustomed to understanding our psychological real estate as a resource for fueling capitalism, rather than a social or personal space. It is the twenty-first-century <*p. 28*> equivalent of Margaret Thatcher's favored slogan TINA--There Is No Alternative--that deflects us away from imagining other ways of structuring our digital lives. In his work as a psychoanalyst, Freud saw firsthand how self-knowledge--the expression and analysis of our mind in therapeutic ways--could help us navigate the challenges of living in society. The current structure of online life not only militates against that objective, it hands over deeply personal information to companies that are not interested in helping us to overcome our problems or develop a functional mind. The companies do not need us as consumers; this is a world in which we are socialized into needing them.

Rather than building connections, let alone a genuinely public space in which people can communicate collectively or buy and sell in the marketplace on equal terms, the companies that profit from the data boom are breaking these spaces down. Data is centralized, with the effect of creating specific and segmented populations based on demographics. "The goal is to distribute, not concentrate, the population," argues professor Bernard E. Harcourt, "to avoid amassing consumers at any one spectacle--so that they spend much more at all the various mini-theatres of consumption." As Turow sees it, the kind of marketing that we are subject to alerts us to our social position: "If you consistently get ads for low-priced cars, regional vacations, fast-food restaurants, and other products that reflect a lower-class status, your sense of the world's opportunities may be narrower than that of someone who is feted with ads for national or international trips and luxury products." He calls these "reputation silos," which have the effect of entrenching the distance people feel between one another. In other words, shared public space begins to vanish; increasingly there is no single collective experience online. The age of the all-powerful consumer is actually one in which we are offered narrower and narrower choices, assigned an identity that reflects, and continuously reproduces, the way in which technology capitalism is shaping our experience of the web. It is a version of what sociologists call "symbolic interactionism," which describes how individuals and societies are constantly producing <*p. 29*> and reproducing identities and norms through social, or in this case digital, interaction.

If we think about the Internet as a place rather than a service, this process of abstract identification is not empowering--it causes fragmentation and distance between people. It creates a world where the population is subject to different framing effects, making for increasingly insurmountable political and social divisions, worlds that stand apart from each other despite nominally existing in a communal space. Gated communities become sealed off from socially isolated public housing projects. The effect is to degrade our sense of belonging, to emphasize the differences in our abstract identities rather than our commonalities. "By emphasizing the individual to an extreme," Turow writes, "the new niche-making forces are encouraging values that diminish the sense of belonging that is necessary to a healthy civic life."

The iconic activist and urban studies writer Jane Jacobs described the importance of understanding "what makes a city center magnetic, what can inject the gaiety, the wonder, the cheerful hurly-burly that make people want to come into the city and to linger there." Jacobs came to prominence in the 1950s and '60s, defending Washington Square Park in New York City from plans to demolish it to make way for an expressway. Her most famous and influential book, *The Death and Life of Great American Cities* (1961) argued that one of the key principles underlying successful cities is the presence of an "intricate and close-grained diversity of uses that give each other constant mutual support." Jacobs rejected the modernist, rationalist design that dominated orthodox urban studies at the time, in which the natural direction of urban renewal was toward planned cities and high-rise buildings, rarely integrated into their surroundings. Jacobs embraced the value of landscapes that allowed people from different backgrounds, with different purposes, to all mix together, and advocated for building cities around this objective.

When it comes to the cities of our psychology, technology capitalism has adopted the mantra of the orthodox urban studies aficionados. The facilitated segregation and curation of non-intersecting <*p. 30*> worldviews shape a psychological landscape that is stripped of diversity. Jacobs would no doubt shudder at the prospect of such banality and isolation.

---

The fragmentation of our online public spaces and the way in which our entire sense of self has become highly porous to influence may have corrosive effects, but that does not mean it is an unpleasant process. Quite the contrary: it is designed to be enjoyable, structured to optimize, at times, a sense of fulfillment. Surveillance capitalism uses our desire for convenience and connection as bait to draw us into using its platforms. It then uses our consent to justify transferring responsibility for its invasive practices onto us. It is akin to organizing an entire city around cars--demolishing neighborhoods and parklands to facilitate the smooth flow of traffic. Parking lots and spaghetti bridges are convenient for drivers, insulated from weather and noise in their bubbles of steel and glass, but they also deprive us of the capacity to experience the charm and surprise of being a pedestrian.

A metaphor frequently used to understand surveillance capitalism comes from George Orwell's novel *1984*, where the all-seeing, all-knowing Big Brother watches our every move through hidden cameras, screens and recorders. Similarly, it is compared to Jeremy Bentham's nineteenth-century model of an "enlightened" prison, the panopticon, where the guard is able to see all of the prisoners all of the time from a central vantage point. Yet both these comparisons fail to capture some important features of our current predicament.

Big Brother and the panopticon worked on the basis that they taught people to police themselves. Surveillance capitalism is generally designed to go unnoticed. While many companies have a vested interest in mining our data and using it to influence us, this tends to work better the less we know about it. As Harcourt explains. "The watching works best not when it is internalized, but when it is absentmindedly forgotten." Target, for example, learned this lesson when the story of the pregnant teen and her unsuspecting father <*p. 31*> made headlines. Such marketing methods appear unnerving and intrusive, rather than impressive.

Mindful of this, plenty of websites operate as data miners in disguise. Dating websites are a good example. The sales pitch of OkCupid is that it takes a scientific approach to matching people, based on survey questions about values and preferences across a range of fields. But what the site does not explicitly tell you, or would rather you forget, is that any data you enter about yourself belongs to them. The company has admitted it has no idea of the relevance of the collected data to the objective of engineering better matches. They basically make it up as they go along by running experiments on their users. As a co-founder of the company put it, rather airily: "Guess what, everybody: if you use the Internet, you're the subject of hundreds of experiments at any given time, on every site. That's how websites work." The money is in the data that they collect and sell to third parties. To this end, OkCupid's parent company, Match Group, owns multiple dating sites--everything from Tinder to CatholicPeopleMeet--that cater to different races, religions, ages and political preferences. It is a form of abstract identification sold as an optimized chance at romantic success.

Marketing messages increasingly hide below the radar, barely even registering with many of us as advertising. In *Black Ops Advertising*, Mara Einstein talks about how Red Bull became a market leader in this area, with countless videos of daring stunts and entertaining feats that seem to bear little relation to the energy drink. Such videos are beautiful and exciting to watch. Only small clues mark them as advertisements, such as the placement of the logo. The subtlety of the marketing is what underpins its appeal. "Years of remote controls, DVRs, and now 'banner blindness' and ad blockers have taught advertisers that consumers are utterly adept at circumventing advertising," Einstein writes. "In response, they have turned to new and improved forms of clandestine marketing." The goal is to influence us to remember brands and imagine buying things without being aware of it. Ultimately, these companies want us to replicate his process by sharing the content and its covert branding, so our <*p. 32*> entire social network becomes a permanent marketplace. It is a way of commodifying and monetizing our social spaces.

This is Freud's pleasure principle writ large--a social experience that is centered around pursuing endless saccharine indulgence with the promise of avoiding reality. The psychological process that Freud identified has been repurposed to suit the aims of capitalism in online spaces. "The programme of becoming happy, which the pleasure principle imposes on us, cannot be fulfilled," wrote Freud, "yet we must not--indeed, we cannot--give up our efforts to bring it nearer to fulfillment." This can take different forms, such as the attainment of pleasure or the avoidance of displeasure. But no matter what we do, Freud noted, "by none of these paths can we attain all that we desire." The pleasure principle drives our behavior, and unless we find ways to manage its insatiability it can become dominant, even overwhelming. Surveillance capitalism has structured our online life so that attempts to limit the influence of the pleasure principle are made difficult and frustrating.

There are many troubling parallels with the electronic gambling machine industry. This industry is built on active and sophisticated attempts by technology designers to create a dynamic of addiction between person and device. Decades before the advent of data miner and marketers, technologists in the gambling industry were pioneering methods of amassing large amounts of personal data about users, cultivating consumer loyalty and finding pain points and precisely timed moments to deliver effective marketing messages. Cultural anthropologist Natasha Schüll has written about how engagement with gambling machines is "a trapping and ultimately annihilating encounter." Venue operators regularly use real-time monitoring of the play of individual consumers--turning gambling machines into surveillance devices--to orchestrate interventions that will keep people engaged. Gamblers become lost in what they call "the zone," with endless play generating the precise balance of stimulation and calm that locks them into subservience to the pleasure principle.

As is the case with data mining and black ops marketing, the industry behind gambling machine design is shadowy, almost <*p. 33*> unseen. Enormous effort goes into cultivating the kind of addiction that sees gamblers destroy themselves. Schüll documents "the pains-taking efforts" by the industry "to organize the kinaesthetic and temporal elements of machine play." Such efforts underscore the fallacy of framing addiction in the language of individual responsibility and willpower. Rather, the cause of addiction is not discretely within the person or the technology but in the dynamic interaction between the two.

The same observation can be applied to surveillance capitalism: digital technology is designed carefully to foster continued engagement that serves the purposes of data miners and black ops marketers. Martínez writes about how the Facebook growth team, responsible for increasing user numbers, used the very same strategies employed by gambling machine designers. The growth team

> exploited every piece of psychological gimcrackery, every tool of visual legerdemain, to turn a pair of eyeballs into a Facebook user ID ... They calculated statistics like clickthrough and conversion rates out to three decimals, and maintained comprehensive databases of user data. Whether via Skinnerian or Pavlovian psychology, they'd figure out the optimal rate to send reminder emails about in-Facebook events (like mentions or new posts from friends) for optimal response.

It is not just social media platforms that use this strategy. Adam Greenfield has written about how we live in a networked condition, whereby the immense functionality of devices like smartphones encourage endless time spent swiping and scrolling. "We become reliant on access to the network to accomplish ordinary goals," he writes. In doing so, we put ourselves at the mercy of devices which constantly extract data and use it to manipulate us with tailored marketing.

For many of us, this is our daily experience of computing and the web. Living online is now such an overwhelming and undeniable experience that there is growing public discussion of how design cultivates addiction behaviors toward digital technology. <*p. 34*> People like Tristan Harris from the Center for Humane Technology have critiqued design features that provide intermittent rewards, create endless newsfeeds, and manipulate our "fear of missing out" and desire for social approval. Harris has a tendency to frame this issue in individualistic terms, at times leaving the broader context unquestioned. His status as a former insider--he worked at Google--means he speaks with undeniable knowledge, but it does not necessarily equip him to provide the necessary critique of technology capitalism. Still, we should listen to such testimonies about the enormous resources being devoted to getting us online, to tune in and drop out. They are vital to understanding the dynamics of the digital spaces we have to navigate every day.

Professor Harcourt describes Facebook's user experience as "the digital equivalent of the perfect hallucinogen, 'soma,' from Aldous Huxley's *Brave New World*--a magical substance without side effects or hangovers, that is perfectly satisfying." Soma is perfectly satisfying to the point where life without it seems troubling and even miserable. Martínez puts it even more bluntly, reflecting on his decision to join the company: "Facebook was legalized crack, and at Internet scale." In this way, the analogy of Orwell's *1984* becomes unhelpful for understanding the phenomenon of abstract identification and data discrimination. As Neil Postman argued back in 1985, Las Vegas, with its slot machines and devotion to entertainment, was the best metaphor for our collective character and aspiration in the age of television--and, I would suggest, the age of digital technology. Rather than the tyranny of fear and hate that characterized Orwell's dystopia, ours is one ruled by the smiling face and its vaudeville entertainment. "Orwell's prophecies are of small relevance," Postman concluded, "but Huxley's are well under way toward being realized."

---

Freud appreciated that living in society is always a compromise between the desire to live a life of pleasure and the realities involved in living as part of a collective. Analysis could help us navigate around the trauma and pain that have befallen us, and not let our <*p. 35*> past determine our present or future. But we also have to survive in a social context and find ways to come to terms with how this inevitably tempers our behavior. This is not just an organizational burden but also an essential part of being human. "The individual only makes sense as a knot of social ties, a network of relations to the others." writes Dolar. Outside the social context we are meaningless, even if it also acts as a burden upon our desires.

The ways in which we build our spaces, both physically and digitally, will influence our capacity to manage our desires and navigate the compromises we must make. They should balance convenience with engagement, and cultivate connection, rather than atomize and segregate. These are exactly the motivations that drove Jane Jacobs to lead a campaign to save Washington Square Park in New York City from a plan by urban designers to build a freeway through it in the late 1950s. The proposed freeway, while certainly convenient for cars, would have destroyed a resource that was used by local people in a granular way, rarely appreciated by planners with grand, modernist visions. "It is very discouraging to do our best to make the city more habitable," wrote Jacobs to the mayor, "and then to learn that the city is thinking up schemes to make it uninhabitable." Ten years later, after countless meetings and protests involving thousands of residents, the plan for the expressway was scrapped. What had been dismissed by senior urban planners as a movement of "a bunch of mothers" had actually saved a part of the city that remains deeply important to its inhabitants.

There is much still to be won and lost in the battle for our online autonomy in the future. As the next generation of web technology improves the integration of all our digital activities, allowing machines to organize even more of our lives, others will continue to learn more about us than we even know ourselves. In this context. focusing on our power over this process as consumers is a mistake: the power being exercised over us is precisely based on our being socialized as consumers. This prepares us to accept a city where every park is paved over to build freeways and every sports field and roller-skating rink is demolished to build a shopping mall. Such <*p. 36*> a city would not be a functional, let alone enjoyable, place to live. But it would be a place where data traders and retailers made a lot of money.

To talk about this process as one conducted with our consent or understanding diminishes the immense effort that goes into facilitating our participation in such operations. It focuses the problem on the individual, rather than the system. It ignores the genuinely held concerns of many about the negative way in which surveillance capitalism affects their lives, and the widespread desire for something different. One of the first research scientists for Facebook, Jeffrey Hammerbacher, famously captured some of this disappointment: "The best minds of my generation are thinking about how to make people click ads." he said. "That sucks."

When Uber first launched in 2010, there was considerable fanfare about how ride sharing was a positive development. It would allow more people to work their own schedule; it would improve transport services to areas traditionally underserved by taxis; it would be environmentally friendly by discouraging car ownership. Uber was intended to complement public transport options, not replace them. In 2015, its then CEO Travis Kalanick announced the company's "simple" goal: "to take 1 million cars off the road in New York City and help eliminate our city's congestion problem for good." It was a classic moment in Silicon Valley optimism, epitomizing the promise of the digital revolution according to technology capitalism.

They were bold claims, and the upshot has been ambiguous at best. Rather than getting cars off the road, the rise of Uber appears to correlate with an increase in traffic congestion. Average travel speeds in central Manhattan have declined 15 percent from 2010. It is not entirely clear why this is happening, but experts think that Uber and other ride-sharing companies are part of the reason. The number of subway riders has dropped, despite population growth. Revenue for the city has also fallen: yellow taxi trips incur a 50-cent surcharge that funds improvements on subways and buses. In other words, the popularity of Uber has meant that public transit options have struggled to remain competitive. London fares no better, with <*p. 37*> more Uber drivers than black cabs now on the roads, reversing much of the environmental and practical gains made by the introduction of the congestion charge.

Uber may be convenient, more enjoyable than taking a packed bus, and cheap in relative terms. But the privatization of mass transit is also making our cities worse. Uber's long game appears to be to dispense with drivers altogether and run a fleet of driverless cars that offer even cheaper rides. It is easy to imagine our cities in constant gridlock, with public transit fallen into disrepair and more public spaces eaten up by widening roads. We will be chauffeured through the smoggy air, logged and tracked under the watchful eye of Uber HQ. From a city planning perspective, it is a world that profits Uber and not many others. This phenomenon is not unlike what is happening to our psychological landscape, as a result of the data mining industry: the cities of our mind are being clogged up by corporations with little interest in planning infrastructure and building skylines to suit our needs, but that prefer to prioritize their bottom line.

One of Jane Jacobs's key insights into what makes cities great was the importance of pedestrians. She felt that cities were best understood by walking around them, and she believed lively streets were critical for creating diverse and vital communities. From this perspective, we can start to see something of an alternative future. It could be to create a psychological topography that welcomes the flâneur, the iconic urban explorer and stroller of the streets who recurs in much literature and philosophy. The French writer Charles Baudelaire described this proverbial character as one whose genius is grounded in curiosity, who is gifted with the capacity to see. "To be away from home and yet to feel at home anywhere, to see the world, to be at the very center of the world, and yet to remain hidden from the world," Baudelaire explained, were some of the pleasures of the flâneur's spirit and independent nature. Later iterations, most notably from Walter Benjamin, highlighted the sensory overload created by consumer capitalism from the perspective of the flâneur, hollowing out his experience.

<*p. 38*> This perspective might hold promise for escape from the drudgery of a data-driven life. For the flâneur to occupy a city--to be enticed to explore it--implies a site of beauty, complexity and surprise. An element of the unexpected, the possibility of interesting encounters, rather than gated communities or soulless high-rises saturated by surveillance; a space cultivated around the needs of people, rather than profit. Can we aim to rebuild such a city psychologically, in resistance to the designs of the data mining industry? Jacobs observed that "every downtown can capitalize on its own peculiar combinations of past and present, climate and topography, or accidents of growth." Ultimately she was excited by the prospect of doing so:

> What a wonderful challenge there is! Rarely before has the citizen had such a chance to reshape the city, and to make it the kind of city that he likes and that others will too. If this means leaving room for the incongruous, or the vulgar or the strange, that is part of the challenge, not the problem. Designing a dream city is easy; rebuilding a living one takes imagination.

We need to protect space in our minds for the vulgar and the strange, for the unpredictable experiences of living free from the influence of commercialism. Like the flâneur or flâneuse, we should aim to cultivate curiosity and the capacity to see our fellow citizens through this liberated lens. The flâneur "participates fully through observation," as one writer put it. If we embrace that mode of being, we can begin to see how we ourselves are being observed by the structures of surveillance capitalism--and stroll with determination toward the objective of dismantling them.

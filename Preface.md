# Preface to the Paperback Edition

<*p.xi*> When I first began writing this book, cracks were emerging in the shiny business model of Silicon Valley. The much-hyped promise of the digital revolution was not being delivered. Technology capitalism depended on predatory business practices, incentivized exploitative modes of work, and undermined democratic institutions. People had started to realize these companies cooperated with governments intent on surveilling their citizens. The experience of being online was like being watched through a one-way mirror.

Just a few short years later, the question is not whether the industry needs to change, but how. Discussions about breaking up big tech are common. Data-extractive technology is often met with criticism. The flexibility of the gig economy has clearly become a millstone around the necks of the most vulnerable workers. Finally, the one-way mirror is revealing its secrets, and we are catching glimpses of how power functions in the digital age.

These are crucial times for understanding where we have been. We need context, perspective, and history if we are to forge a path that gives us the best chance of tackling profound problems like climate change, wealth inequality, and the failures of social democracies. Technology has a role to play in helping us address these challenges, but not in its current form.

<*p.xii*> As I write this now, the world is settling in to the new normal generated by the Covid-19 pandemic. If some fractures were emerging in 2016 as to the promise of the digital age, the pandemic has been like an acid wash, seeping into our daily lives, stripping them back to their fundamentals, and corroding and deepening the fissures that predated this moment. These have been years of misery and death for many, and it is painful to see the consequences of mismanagement by those in power visited upon everyday people in the most visceral ways.

But the ongoing crises created by the pandemic are also opportunities. This is particularly true for those interested in rerouting our society in a more democratic direction. The Internet is central to our lives like never before, and its brilliance as a creation of human ingenuity is on full display in the age of social distancing. We need to find ways to protect its openness and accessibility, and to encourage the collective creativity that underpinned its development.

However, those in power are not idle. Already they are seeking to encode permanence into various aspects of this state of exception, to shore up status and profits for themselves. Technology is and will continue to play a role in this crisis and its aftermath, as well as in more pressing crises that are yet to come. It behoves us to consider carefully who is making decisions about how technology is built and used, and why.

---

It is worth remembering that Mark Zuckerberg reacted with bemusement when his staff presented him with the idea that Facebook may have played a role in the surprising outcome of the 2016 US elections. The business model of the platform was to maximize its capacity to extract information from users--and filter bubbles, viral disinformation, and polarization were all consequences of trying to keep people on their devices. Zuckerberg's nonplussed reaction now seems quaint, if not dangerous and arrogant. In the years since, the company has ended up devoting significant resources to mitigate these criticisms and take more responsibility for its curatorial role. Zuckerberg now talks openly about the need for regulation. The <*p.xiii*> company has set up its own oversight board to scrutinize internal decisions. The idea that Facebook should operate wholly unfettered by regulation is no longer tenable; its executive leadership has already shifted its strategy towards limiting and controlling the growing impulse for regulatory reform.

Facebook has seen which way the wind is blowing. It is clear that many people, and many politicians, think tech companies have far too much power over our online lives. This growing awareness is finding expression as political action in the United States. In the last half of 2020, the CEOs of the big four tech companies have been called to give evidence before the House Judiciary Committee during its investigation into breaches of antitrust law, and some of them have given even more evidence in hearings before the Senate Committee on Commerce, Science, and Transportation in discussions of content moderation. The House Judiciary Committee delivered a forthright report, recommending all manner of regulatory reform. To top it all off, Google was sued by the Department of Justice for anticompetitive conduct, and Facebook was sued by the FTC for illegal monopolization. Technology capitalism will no longer be permitted to move fast and break things. People are demanding they clean up the mess they have created.

If some form of regulation appears to be a fait accompli in the US, the form this takes will be critical. A Biden administration will not be a simple repeat of the Obama years, in which Silicon Valley types were treated as entrepreneurial saviours of the American dream. The time has passed for that. But the leaders of technology capitalism have ingratiated themselves with the center-left, and we should expect them to do the bidding of their industry. Technology companies have spent hundreds of millions of dollars lobbying lawmakers in recent years. After having shown such wanton disregard for the social consequences of their business model, we cannot let the tech industry write the rules designed to address these problems.

Other parts of the Democratic Party are falling into line behind the idea that antitrust law is the solution. This drive has good historical credentials, which I talk about in the following pages. Antitrust <*p.xiv*> law has traditionally not been confined solely to questions of consumer welfare, but historically has been very much motivated by the distribution of power in social democracies. Perhaps most prominently, Senator Elizabeth Warren has built a considerable amount of her political support around the idea that big companies need to be broken up. There is something to be said for Zephyr Teachout's argument that we need to "start thinking about the FTC as a central site of democratic politics." Effective regulation of these companies cannot simply be about writing laws that hold them to account directly but must also empower executive and regulatory institutions to do their job better. Teachout has astutely observed that the risk "is not that government won't act, but that it will act just enough to make it look like it is doing something, but not enough to break up big tech's power."

But, to this end, a focus on antitrust law cannot be the only solution proposed by progressives either. A functional marketplace for digital services is a dangerously unambitious goal. We shouldn't let go of the idea that the infrastructure of digital life, for both the Internet and the web, ought to be a site of public investment. It is now more obvious than ever that access to the network is a fundamental right, not something that should be left to the industry to provide. To tackle disinformation, a problem that is in many ways a product of the data-extractive practices of social media companies, we need independent, publicly funded media and platforms that can help us to make sense of the world, to find common narratives and clarify points of division. Such public institutions could also be a site of experimentation with digital public participation. Instead of trying to create an industry of many small competing firms, designed to optimize the functionality of the market, perhaps it is time to experiment instead with democratic control and public ownership, to orient the great potential of the digital age towards the common good.

There are precedents for this. The development of the Internet backbone itself was a product of public investment, as I discuss in a chapter of this book. Industries, like the automotive industry, have <*p.xv*> been subject to wholesale regulation when it became clear that the market prioritized profit over safety. We can and should return to a world in which bold and expansive public investment is a fundamental part of our digital policy and regulators are unafraid to take on capital.

Moreover, breaking up big tech is not the same as having better laws that directly protect privacy. This is especially true outside of the United States, where there is often less capacity to deploy antitrust legal tools against gigantic companies. As regulators and policy makers contend with the problem of unaccountable tech companies all around the world, we are presented with the opportunity to appraise the insidious role of capitalism in the digital revolution. We need to find ways to reorganize the political economy of the web, to undercut the data mining industry and the associated benefits for government sureillance regimes. We ought to hand power back to people, to allow us to know the online worlds we occupy and thereby regain a sense of agency over our experiences within them. This requires laws that are predicated on treating us as holders of rights rather than consumers to be groomed in profitable desires. This will require experimentation with greater ownership over personal information for individuals, and corporate taxes that curtail the incentive to commodify every online engagement.

It is pleasing to see how regulators and lawmakers are beginning to address the concerns expressed by so many about technology capitalism. But this is not a moment to hand to them the responsibility for addressing such problems wholesale. Rather, it is the beginning of the conversation, a chance to widen the gaps that have emerged between our expectations of the world and reality, and to see how alternatives might take shape.

---

The other defining feature of the present moment is the tendency of governments around the world to experiment with various technologies of sureillance in the name of public health, especially in the midst of the pandemic. Facial recognition is being rolled out in more and more public spaces, used by US police to track protestors and <*p.xvi*> Russian authorities to map the pandemic, often without our consent or even knowledge. Citizens are being cajoled into downloading contact-tracing apps. Highly sophisticated technology is being deployed at borders to track the flow of people. The irony is that with networked technology borders are less of a geographic threshold and more of social construct, used primarily to manage, control, and terrorize--rather than simply to regulate a flow of people and goods.

For technology to be used effectively to stop the spread of the pandemic, as with almost any social problem, it would necessarily mean compromising some rights as a contribution to the collective good. Such a compromise might be reasonable, if the public could trust those in charge with administering it. For many good reasons, that trust is lacking. The problem is that those in power have failed repeatedly to show respect for our rights and dignity. Those failures have consequences that, invariably, are borne by ordinary people. 

This particular mode of operating--where mass surveillance is opportunistically framed as a necessary public good--has a long history. For generations, public safety has been used by politicians as cover to deploy technology that rebalances power away from people, towards government. This is one of the arguments I make in the following pages, to draw a line between the first modern police force and our contemporary digital surveillance state. As capitalism established itself in eighteenth-century England, a professional police force was created to keep workers on the docks of the River Thames in their place. Surveillance was an invaluable technique for doing this work cheaply and efficiently. The prevention of crime was treated as synonymous with public safety, but in many ways it was about managing and entrenching social division, and quashing resistance to the status quo, which was steeped in exploitation and inequality.

Over two hundred years later, the surveillance state is still responsible for preventing crime, and has built an invasive digital apparatus for this purpose. The crimes often used to justify the expansion of this apparatus are invariably the worst kind, like terrorism, <*p.xvii*> espionage, and pedophilia (or as I like to call them, the three horsemen of the authoritarian apocalypse). The sheer immorality of such offenses almost entirely forecloses debate about the tactics used to guard against them. Similarly, in the wake of a global pandemic, technological projects to combat the virus are imbued with heavy moralism, making it difficult to debate the practical difficulties and philosophical concerns associated with using technology to keep tabs on citizens at scale, with very limited accountability.

This tendency to justify surveillance in the name of safety is a remarkably unifying theme of global politics. Though many American politicians like to talk about freedom from excessive government, they remain heavily committed to funding and maintaining national security and law enforcement agencies. They are, indeed, resistant to the very idea that there could be different ways of operating. A whole private industry has also developed to contribute to this program of work, in essence to build up a robust social graph of the population. As the revelations of whistle blowers have shown us, the aim of the surveillance state is to anticipate dissent, manage conflict, and preserve the status quo, with all its galling injustice.

Meanwhile, across the Pacific, the Chinese government refines and perfects its nefarious social credit system and complementary networks of surveillance technology. Powerful technology in the hands of elected presidents is a worry, but in the hands of autocrats, it is a frightening phenomenon. We can see this play out in the daily experiences of the poor and marginalized living in China, who become locked out of society. This prospect becomes a threat that hangs over the head of every would-be dissident. We can glimpse the struggle to retain the political hegemony for the ruling elite in more captivating moments when protestors in Hong Kong bravely took to the streets to demand a better future. These people were facing off, frequently in creative ways, against police using sophisticated forms of tracking technology in protection of their powerful bosses.

The point is that Beijing and Washington may often highlight their differences in diplomacy but, like so many nation-states, they have <*p.xviii*> approached the opportunities presented by the digital revolution in similar ways. A commitment to surveillance is held in common by the ruling elite in both liberal democracies like the United States and authoritarian regimes like China. The United States relies heavily on private industry to do this work, whereas in China it is state run, but upon examination of the social and political bases of these programs, the differences begin to melt away.

In many ways, then, we must call for a plague on both their houses. The working people of all nations have a common interest in ensuring that the potential of the digital revolution is not squandered on projects designed by those in power to maintain social control. Global superpowers with imperial aspirations cannot be redeemed no matter how slickly they present themselves. Everyday people of the world have an interest in rejecting their rhetoric and finding common cause and solidarity that transcend national borders.

---

Digital technology can be a tool of political liberation--especially the Internet, as a borderless information network--but it will require organizing and activism to make it so. We need to find ways to change the existing structures of power, which have been so successful for the elite in many societies characterized by class division.

In my view, the answer is to build movements that force policy makers to feel they are responsible to their constituents and encourage them to realize their jobs will be at risk should they make decisions that are not in the public interest. Companies should feel existential dread at the prospect of selling out their users and profiting through data-mining private information. Given that so many countries are struggling with similar questions about how to hold governments and companies accountable in the digital age, this way of organizing naturally lends itself to a kind of digital internationalism.

The moment in which we find ourselves is both frightening and exciting. People are beginning to reject the political bargain they have been sold, where we must all give up privacy and autonomy <*p.xix*> for public safety and convenience. The experience of the pandemic demonstrates that governments need to earn a social licence to use technology in particular ways, and this requires that they stop behaving like secretive autocrats. Companies need to stop demonstrating haughty indifference to the problems they have helped create. It is no longer possible to treat human rights as an afterthought in tech initiatives or dismiss privacy issues as concerns only held by people in tinfoil hats. That is an emerging political dynamic that was hard fought for, and must be defended.

At this moment, when so much hangs in the balance, when the world is contending with the vast changes wrought by a pandemic and imagining what more might be coming with the specter of climate change, we have an opportunity to argue for technology that is democratic--that is, designed in ways that are decentralized and use open-source principles. We can highlight the importance of transparency and accountability as integral parts of the design process, rather than allow these concepts to be an afterthought patched on later when the opportunity to gain public trust has already been squandered. We also need to learn to say no if we cannot offer such protections. Maybe we need a moratorium on government and corporate development of facial recognition technology, for example, a conclusion several major companies have already drawn. Maybe we need to ask these questions about technology more often: if it cannot be built in a way that protects the most vulnerable, that ermpowers the disenfranchised, should it be built at all?

We can reclaim the possibility of a different future by using history as our guide. In the following chapters, I argue that social movements and thinkers from the past can help us better understand the problems presented by the digital age. Far from being novel concerns, technological questions we are confronting today often have a much longer history- one that predates the Internet, the web, and the computer itself. My hope is that it will embolden you, my generous and thoughtful readers, to take up the challenge of using digital technology as a tool to take back power, to allow the web to be a place of human connection and flourishing.

<*p.xx*>

There is a crack in everything, Leonard Cohen liked to remind us, and that is how the light gets in. The last four years have shed light on the problems created by the digital revolution. Our job is to use that light to navigate towards a more democratic digital tomorrow.

*Lizzie O'Shea*
*Melbourne, 2021*
